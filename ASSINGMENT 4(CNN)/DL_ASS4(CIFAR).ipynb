{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "DL_ASS4(CIFAR).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkvLxjy_lX5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import random as rand\n",
        "import numpy\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt \n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87S8r8a1lX5W",
        "colab_type": "code",
        "outputId": "6f4fad94-077c-4ec5-c2e1-0be2da367fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 169697280/170498071 [00:12<00:00, 17204719.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffeiQ4FTlX5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 10000\n",
        "num_epochs = n_iters / (len(trainset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=testset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOzhGVaolq9b",
        "colab_type": "code",
        "outputId": "1baf0336-b254-4363-dac2-444e7076cba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2KDanxslX5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6RIBTMcowZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN()\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "#######################\n",
        "#  USE GPU FOR MODEL  #\n",
        "#######################\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqfWEE-Jo8p7",
        "colab_type": "code",
        "outputId": "be0714d9-e957-4203-a987-60d44dc72328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    loss_values = []\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        \n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # wrap them in Variable\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        if epoch > 16:\n",
        "            for group in optimizer.param_groups:\n",
        "                for p in group['params']:\n",
        "                    state = optimizer.state[p]\n",
        "                    if state['step'] >= 1024:\n",
        "                        state['step'] = 1000\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Normalizing the loss by the total number of train batches\n",
        "    running_loss /= len(train_loader)\n",
        "    loss_values.append(running_loss)\n",
        "    \n",
        "\n",
        "    # Calculate training/test set accuracy of the existing model\n",
        "    #train_accuracy = calculate_accuracy(trainloader, opt.is_gpu)\n",
        "    #test_accuracy = calculate_accuracy(testloader, opt.is_gpu)\n",
        "\n",
        "    print(\"Iteration: {0} | Loss: {1} \".format(epoch+1, running_loss))\n",
        "\n",
        "    # save model\n",
        "    \"\"\"if epoch % 50 == 0:\n",
        "        print('==> Saving model ...')\n",
        "        state = {\n",
        "            'net': net.module if opt.is_gpu else net,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, '../checkpoint/ckpt.t7')\n",
        "        \"\"\"\n",
        "\n",
        "print('==> Finished Training ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 | Loss: 0.05808339566970244 \n",
            "Iteration: 2 | Loss: 0.05824617545632645 \n",
            "Iteration: 3 | Loss: 0.05216355744097382 \n",
            "Iteration: 4 | Loss: 0.05119319553580135 \n",
            "Iteration: 5 | Loss: 0.04821598399989307 \n",
            "Iteration: 6 | Loss: 0.04887939654150978 \n",
            "Iteration: 7 | Loss: 0.04564704450918362 \n",
            "Iteration: 8 | Loss: 0.041646327270660546 \n",
            "Iteration: 9 | Loss: 0.042067258310038595 \n",
            "Iteration: 10 | Loss: 0.04377115397481248 \n",
            "Iteration: 11 | Loss: 0.04091923156287521 \n",
            "Iteration: 12 | Loss: 0.0412195207105251 \n",
            "Iteration: 13 | Loss: 0.03663436589867342 \n",
            "Iteration: 14 | Loss: 0.03816774710640311 \n",
            "Iteration: 15 | Loss: 0.03654655154934153 \n",
            "Iteration: 16 | Loss: 0.036453073685057465 \n",
            "Iteration: 17 | Loss: 0.03541739800781943 \n",
            "Iteration: 18 | Loss: 0.025432630659313872 \n",
            "Iteration: 19 | Loss: 0.02167408222029917 \n",
            "Iteration: 20 | Loss: 0.023597587706986816 \n",
            "==> Finished Training ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh3ugaWpuFdw",
        "colab_type": "code",
        "outputId": "d056a1ae-643b-490d-c7ca-c114986af155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# Iterate through test dataset\n",
        "for images, labels in test_loader:\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        images = Variable(images.cuda())\n",
        "    else:\n",
        "        images = Variable(images)\n",
        "                \n",
        "    # Forward pass only to get logits/output\n",
        "    outputs = model(images)\n",
        "                \n",
        "    # Get predictions from the maximum value\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "    # Total number of labels\n",
        "    total += labels.size(0)\n",
        "                \n",
        "              \n",
        "    # Total correct predictions\n",
        "    if torch.cuda.is_available():\n",
        "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "    else:\n",
        "        correct += (predicted == labels).sum()\n",
        "            \n",
        "accuracy = 100 * correct / total\n",
        "print(\"Accuracy on total test data: {}%\".format(accuracy.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on total test data: 80%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}